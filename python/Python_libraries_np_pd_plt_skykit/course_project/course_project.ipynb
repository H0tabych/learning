{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ca84de-5a47-43af-9b0d-a7cc6767984d",
   "metadata": {},
   "source": [
    "# Курсовой проект для курса \"Python для Data Science\"\n",
    "\n",
    "Материалы к проекту (файлы):\n",
    "train.csv\n",
    "test.csv\n",
    "\n",
    "Задание:\n",
    "Используя данные из train.csv, построить\n",
    "модель для предсказания цен на недвижимость (квартиры).\n",
    "С помощью полученной модели предсказать\n",
    "цены для квартир из файла test.csv.\n",
    "\n",
    "Целевая переменная:\n",
    "Price\n",
    "\n",
    "Метрика:\n",
    "R2 - коэффициент детерминации (sklearn.metrics.r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58188175-b069-4f66-9670-b558450e241f",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0ad149a-7ead-47da-a5eb-22af45e37d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error as mse\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa98590-f6db-481c-ae8c-d8491a60f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(true_values, pred_values, save=False):\n",
    "    \"\"\"Оценка качества модели и график preds vs true\"\"\"\n",
    "    \n",
    "    print(\"R2:\\t\" + str(round(r2_score(true_values, pred_values), 3)) + \"\\n\" +\n",
    "          \"RMSE:\\t\" + str(round(np.sqrt(mse(true_values, pred_values)), 3)) + \"\\n\" +\n",
    "          \"MSE:\\t\" + str(round(mse(true_values, pred_values), 3))\n",
    "         )\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    \n",
    "    sns.scatterplot(x=pred_values, y=true_values)\n",
    "    plt.plot([0, 500000], [0, 500000], linestyle='--', color='black')  # диагональ, где true_values = pred_values\n",
    "    \n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('True values')\n",
    "    plt.title('True vs Predicted values')\n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig(REPORTS_FILE_PATH + 'report.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26585adc-2383-4ef8-97e2-243728a068a0",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c908529-2723-4f5e-b5f7-ba92bc3843ca",
   "metadata": {},
   "source": [
    "### Прописываем пути"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306586ab-0b97-4f8a-a30b-39bd324ae365",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainf = \"train.csv\"\n",
    "testf = \"test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb033f-edc1-4d47-834f-b59994955b57",
   "metadata": {},
   "source": [
    "### Загружаем данные в память"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2c6a99-98d1-460e-a51c-321db62812df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(trainf)\n",
    "test_df = pd.read_csv(testf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a73072-6734-4878-bda8-c57103e67914",
   "metadata": {},
   "source": [
    "### Описание данных\n",
    "- Id - идентификационный номер квартиры\n",
    "- DistrictId - идентификационный номер района\n",
    "- Rooms - количество комнат\n",
    "- Square - площадь\n",
    "- LifeSquare - жилая площадь\n",
    "- KitchenSquare - площадь кухни\n",
    "- Floor - этаж\n",
    "- HouseFloor - количество этажей в доме\n",
    "- HouseYear - год постройки дома\n",
    "- Ecology_1, Ecology_2, Ecology_3 - экологические показатели местности\n",
    "- Social_1, Social_2, Social_3 - социальные показатели местности\n",
    "- Healthcare_1, Helthcare_2 - показатели местности, связанные с охраной здоровья\n",
    "- Shops_1, Shops_2 - показатели, связанные с наличием магазинов, торговых центров\n",
    "- Price - цена квартиры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a27270-0a39-45f7-a9ec-781d128a673d",
   "metadata": {},
   "source": [
    "### Уменьшение объема памяти, который занимает датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e955f0-6725-470f-8651-aa0c376bb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2c60843-9868-48b4-84e0-dbab3cc88bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1.53 MB\n",
      "Memory usage after optimization is: 0.49 MB\n",
      "Decreased by 68.1%\n"
     ]
    }
   ],
   "source": [
    "train_df = reduce_mem_usage(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd4d826-3c0b-4e01-bebc-6cc8c4a0c573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.72 MB\n",
      "Memory usage after optimization is: 0.22 MB\n",
      "Decreased by 70.3%\n"
     ]
    }
   ],
   "source": [
    "test_df = reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb6a313-5a6b-448a-a769-4c827c71b7d8",
   "metadata": {},
   "source": [
    "## Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5be37d6-8ea6-460e-a105-bb18ce42adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor():\n",
    "    def __init__(self):\n",
    "        self.min_max_floor_msk = (1, 95) # ВМоскве нет домов выше 95 этажей\n",
    "        self.min_life_square = 14 # Жилая площадь не может быть менее 14 кв.м. согласно законодательству\n",
    "        self.min_kitchen_square = 5\n",
    "        self.max_rooms = 5\n",
    "        self.median_year = None\n",
    "        self.max_floor_for_district = None\n",
    "        self.pivot_rooms = None # сводная таблица медиан этажей по годам\n",
    "        self.filter_square = None # фильтр для площадей в которые верим\n",
    "        self.pivot_square = None # сводная таблица площадей по годам\n",
    "        self.pivot_lsquare = None # сводная долей жилых площадей от общей площади по числу комнат\n",
    "        self.pivot_ksquare = None # сводная долей кухонных площадей от общей площади по числу комнат\n",
    "        self.districts_healthcare = None\n",
    "        self.medians = None\n",
    "        \n",
    "    def fit(self, df):\n",
    "        \n",
    "        # Приводим в порядок года\n",
    "        self.median_year = df.loc[df.HouseYear < datetime.now().year].\\\n",
    "            pivot_table(values=\"HouseYear\", index=\"DistrictId\", columns=\"HouseFloor\", aggfunc=np.median)\n",
    "        self.transform_year(df)\n",
    "        \n",
    "        # Приводим в порядок этажи\n",
    "        self.max_floor_for_district = df.loc[df.HouseFloor < self.min_max_floor_msk[1]].\\\n",
    "            pivot_table(values=\"HouseFloor\", index=\"DistrictId\", columns=\"HouseYear\", aggfunc=np.max)\n",
    "        self.transform_floor(df)\n",
    "        \n",
    "        # Приводим в порядок комнаты\n",
    "        filter_rooms = (df.Square > df.LifeSquare) & (df.Square > df.KitchenSquare) &\\\n",
    "                (df.LifeSquare > df.KitchenSquare) & (df.Rooms <= self.max_rooms) & \\\n",
    "                ((df[[\"Square\", \"LifeSquare\", \"KitchenSquare\", \"Rooms\"]] > 0).all(axis=1))\n",
    "        \n",
    "        self.pivot_rooms = df.loc[filter_rooms].\\\n",
    "            pivot_table(index=\"Rooms\", columns=\"HouseYear\", values=\"Square\", aggfunc=np.median)\n",
    "\n",
    "        for r, row in self.pivot_rooms.iterrows():\n",
    "            for y in row.index[row.isnull()].tolist():\n",
    "                dif = np.abs(row.index[~row.isnull()] - y).tolist()\n",
    "                new_y = row.index[~row.isnull()][dif.index(np.min(dif))]\n",
    "                self.pivot_rooms.loc[r, y] = self.pivot_rooms.loc[r, new_y]\n",
    "        self.trainsform_room(df)\n",
    "        \n",
    "        # Приводим в порядок площадь\n",
    "        self.filter_square = \"(df.Square > df.LifeSquare) & (df.Square > df.KitchenSquare) &\\\n",
    "            (df.KitchenSquare != 0) & (df.Square >= df.LifeSquare + df.KitchenSquare) &\\\n",
    "            (df.LifeSquare >= self.min_life_square) & (df.KitchenSquare >= self.min_kitchen_square) &\\\n",
    "            (df.LifeSquare > df.Square - df.LifeSquare - df.KitchenSquare)\"\n",
    "        \n",
    "        self.pivot_square = df.loc[eval(self.filter_square)].\\\n",
    "            pivot_table(index=\"Rooms\", columns=\"HouseYear\", values=\"Square\", aggfunc=[np.min, np.max, np.median])\n",
    "        \n",
    "        for foo in (\"amin\", \"amax\", \"median\"):\n",
    "            for r, row in self.pivot_square.loc[:, foo].iterrows():\n",
    "                for y in row.index[row.isnull()].tolist():\n",
    "                    dif = np.abs(row.index[~row.isnull()] - y).tolist()\n",
    "                    new_y = row.index[~row.isnull()][dif.index(np.min(dif))]\n",
    "                    self.pivot_square.loc[r, (foo, y)] = self.pivot_square.loc[r, (foo, new_y)]\n",
    "        \n",
    "        self.pivot_lsquare = df.loc[eval(self.filter_square)]\n",
    "        self.pivot_lsquare.loc[:, \"div\"] = (self.pivot_lsquare.loc[:, \"Square\"] / self.pivot_lsquare.loc[:, \"LifeSquare\"])\n",
    "        self.pivot_lsquare = self.pivot_lsquare.pivot_table(index=\"Rooms\", columns=\"HouseYear\", values=\"div\", aggfunc=\"median\")\n",
    "        \n",
    "        for r, row in self.pivot_lsquare.iterrows():\n",
    "            for y in row.index[row.isnull()].tolist():\n",
    "                dif = np.abs(row.index[~row.isnull()] - y).tolist()\n",
    "                new_y = row.index[~row.isnull()][dif.index(np.min(dif))]\n",
    "                self.pivot_lsquare.loc[r, y] = self.pivot_lsquare.loc[r, new_y]\n",
    "                \n",
    "        self.pivot_ksquare = df.loc[eval(self.filter_square)]\n",
    "        self.pivot_ksquare.loc[:, \"div\"] = self.pivot_ksquare.loc[:, \"Square\"] / self.pivot_ksquare.loc[:, \"KitchenSquare\"]\n",
    "        self.pivot_ksquare = self.pivot_ksquare.pivot_table(index=\"Rooms\", columns=\"HouseYear\", values=\"div\", aggfunc=\"median\")\n",
    "        \n",
    "        for r, row in self.pivot_ksquare.iterrows():\n",
    "            for y in row.index[row.isnull()].tolist():\n",
    "                dif = np.abs(row.index[~row.isnull()] - y).tolist()\n",
    "                new_y = row.index[~row.isnull()][dif.index(np.min(dif))]\n",
    "                self.pivot_ksquare.loc[r, y] = self.pivot_ksquare.loc[r, new_y]\n",
    "        \n",
    "        self.transform_square\n",
    "        \n",
    "        # Healthcare_1\n",
    "        \n",
    "        self.districts_healthcare =\\\n",
    "            df.groupby(['DistrictId'])['Healthcare_1'].agg('mean').to_dict()\n",
    "        \n",
    "           \n",
    "    def transform(self, df):\n",
    "        \n",
    "        # Приводим в порядок года\n",
    "        df = self.transform_year(df)\n",
    "        \n",
    "        # Приводим в порядок этажи\n",
    "        df = self.transform_floor(df)\n",
    "        \n",
    "        # Приводим в порядок комнаты\n",
    "        df = self.trainsform_room(df)\n",
    "        \n",
    "        # Приводим в порядок площадь\n",
    "        df = self.transform_square(df)\n",
    "        \n",
    "        # Бнаризация экологических показателей и магазинов\n",
    "        df.replace({'Ecology_2': {'A': 0, 'B': 1}}, inplace=True)\n",
    "        df.replace({'Ecology_3': {'A': 0, 'B': 1}}, inplace=True)\n",
    "        df.replace({'Shops_2': {'A': 0, 'B': 1}}, inplace=True)\n",
    "        \n",
    "        \n",
    "        # Приводим в порядок показатель здравоохранения\n",
    "        self.medians = df.median()\n",
    "             \n",
    "        df.loc[df['Healthcare_1'].isna(), 'Healthcare_1'] = df['DistrictId'].map(self.districts_healthcare)\n",
    "        df['Healthcare_1'].fillna(self.medians.Healthcare_1, inplace=True)       \n",
    "        \n",
    "        q_max = np.quantile(df['Healthcare_1'], q=0.9)\n",
    "        df['Healthcare_1'].clip(upper=q_max, axis=0, inplace=True)\n",
    "        \n",
    "    \n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def transform_year(self, df):\n",
    "        for i, row in df.loc[df.HouseYear > datetime.now().year].iterrows():\n",
    "            df.loc[i, \"HouseYear\"] = round(self.median_year.loc[row.loc[\"DistrictId\"], row.loc[\"HouseFloor\"]])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def transform_floor(self, df):\n",
    "        for i, row in df.loc[(df.HouseFloor > self.min_max_floor_msk[1]) | (df.HouseFloor == 0)].iterrows():\n",
    "            df.loc[i, \"HouseFloor\"] = self.max_floor_for_district.loc[row.loc[\"DistrictId\"], row.loc[\"HouseYear\"]] or \\\n",
    "               self.max_floor_for_district.loc[row.loc[\"DistrictId\"]-4:row.loc[\"DistrictId\"]+4,\\\n",
    "                                            row.loc[\"HouseYear\"]-4:row.loc[\"HouseYear\"]+4].max().max()\n",
    "            \n",
    "            df.loc[df.HouseFloor.isnull(), \"HouseFloor\"] =\\\n",
    "            self.max_floor_for_district.loc[row.loc[\"DistrictId\"]].median()\n",
    "            \n",
    "        df.loc[(df.HouseFloor < df.Floor), [\"HouseFloor\", \"Floor\"]] =\\\n",
    "            df.loc[(df.HouseFloor < df.Floor), [\"Floor\", \"HouseFloor\"]].values\n",
    "                        \n",
    "        return df\n",
    "    \n",
    "    def trainsform_room(self, df):\n",
    "        for i, row in df.loc[(df.Rooms == 0) | (df.Rooms > self.max_rooms)].iterrows():\n",
    "            df.loc[i, \"Rooms\"] =\\\n",
    "                (self.pivot_rooms.loc[:, row[\"HouseYear\"]] - row[\"Square\"]).\\\n",
    "                 abs().sort_values().index[0]\n",
    "            \n",
    "        return(df)\n",
    "    \n",
    "    def transform_square(self, df):\n",
    "        df.Square, df.LifeSquare = np.where((df.Square < df.LifeSquare) &\\\n",
    "                                                (1.5*df.Square >= df.LifeSquare ),\\\n",
    "                                                (df.LifeSquare, df.Square), (df.Square, df.LifeSquare))\n",
    "        \n",
    "        for r in df.loc[~eval(self.filter_square)].Rooms.unique():\n",
    "            for y in df.loc[~eval(self.filter_square)].HouseYear.unique():\n",
    "                if y not in self.pivot_square.loc[r, \"amin\"].index:             \n",
    "                    dif = np.abs(self.pivot_square.loc[r, \"amin\"].index - y).tolist()\n",
    "                    y1 = self.pivot_square.loc[r, \"amin\"].index[dif.index(np.min(dif))]\n",
    "                else:\n",
    "                    y1 = y\n",
    "                    \n",
    "                flt = (df.Rooms == r) & (df.HouseYear == y) & (df.Square < self.pivot_square.loc[r, (\"amin\", y1)])\n",
    "                df.loc[flt, \"Square\"] = self.pivot_square.loc[r, (\"median\", y1)]\n",
    "                flt = (df.Rooms == r) & (train_df.HouseYear == y) & (df.Square > self.pivot_square.loc[r, (\"amax\", y1)])\n",
    "                df.loc[flt, \"Square\"] = self.pivot_square.loc[r, (\"median\", y1)]\n",
    "                \n",
    "                flt = (df.Rooms == r) & (df.HouseYear == y) &\\\n",
    "                             ((df.Square < df.LifeSquare) |\\\n",
    "                              df.LifeSquare.isnull() |\\\n",
    "                              (df.LifeSquare < self.min_life_square))\n",
    "                df.loc[flt, \"LifeSquare\"] = df.loc[flt, \"Square\"] / self.pivot_lsquare.loc[r, y1]\n",
    "                flt = (df.Rooms == r) & (df.HouseYear == y) &\\\n",
    "                             ((df.Square < df.LifeSquare) |\\\n",
    "                              df.LifeSquare.isnull() |\\\n",
    "                              (df.LifeSquare > self.pivot_lsquare.loc[r].max()))\n",
    "                df.loc[flt, \"LifeSquare\"] = df.loc[flt, \"Square\"] / self.pivot_lsquare.loc[r, y1]\n",
    "                \n",
    "                flt = (df.Rooms == r) & (df.HouseYear == y) &\\\n",
    "                       ((df.Square < df.KitchenSquare) |\\\n",
    "                        (df.KitchenSquare == 0) |\\\n",
    "                        (df.KitchenSquare < 5))\n",
    "                df.loc[flt, \"KitchenSquare\"] = df.loc[flt, \"Square\"] / self.pivot_ksquare.loc[r, y1]\n",
    "                flt = (df.Rooms == r) & (df.HouseYear == y) &\\\n",
    "                       ((df.Square < df.KitchenSquare) |\\\n",
    "                        (df.KitchenSquare == 0) |\\\n",
    "                        (df.KitchenSquare > self.pivot_ksquare.loc[r].max()))\n",
    "                df.loc[flt, \"KitchenSquare\"] = df.loc[flt, \"Square\"] / self.pivot_ksquare.loc[r, y1]\n",
    "        \n",
    "        return(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8515f77-a9fe-4eb1-aa3c-92a376f265ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator:\n",
    "    def __init__(self):\n",
    "        self.district_price_per_square = None\n",
    "        self.min_sq = None\n",
    "        self.max_sq = None\n",
    "        \n",
    "    def fit(self, df):   \n",
    "        self.min_sq = np.quantile(df['Square'], q=0.005)\n",
    "        self.max_sq = np.quantile(df['Square'], q=0.995)\n",
    "        \n",
    "        self.district_price_per_square = df.groupby(['DistrictId'])['Price'].agg('median') \\\n",
    "        / df.groupby(['DistrictId'])['Square'].agg('median') \n",
    "        \n",
    "    def transform(self, df):\n",
    "        df[\"div_square\"] = df.Square / (df.LifeSquare + df.KitchenSquare)\n",
    "        \n",
    "        self.district_price_per_square.to_dict()\n",
    "        df['DistrictPrice'] = df['DistrictId'].map(self.district_price_per_square)\n",
    "        \n",
    "        self.median_district_price_per_square = df['DistrictPrice'].median()\n",
    "        df['DistrictPrice'].fillna(self.median_district_price_per_square, inplace=True)    \n",
    "        \n",
    "        floor_bins = [0, 4, 7, 12, df['Floor'].max()]\n",
    "        df['Floor_cat'] = pd.cut(df['Floor'], bins=floor_bins, labels=False)\n",
    "        df['Floor_cat'].fillna(-1, inplace=True) \n",
    "                \n",
    "        return df\n",
    "    \n",
    "    def drop_outliers(self, df):\n",
    "        df = df.loc[(df['Square'] > self.min_sq) & (df['Square'] < self.max_sq)]\n",
    "        \n",
    "        return(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73c769-1930-4536-819a-7a4df72394c8",
   "metadata": {},
   "source": [
    "Сделаем столбец \"Id\" индексом, т.к. он уникален для каждого набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d6b30f-16a9-41bb-b979-92c8ae522581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Id.size - train_df.Id.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc8c0193-8395-4bce-9e12-0ffdbdb337a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.Id.size - test_df.Id.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb6d636f-4986-4a85-892f-8958c4a0f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.set_index(\"Id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0adb59dc-8012-4ac2-a76e-3a451a4c1e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.set_index(\"Id\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5fd7e2-b6bf-44ea-9789-3c4c7ff92f8b",
   "metadata": {},
   "source": [
    "Преобразование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3973e62d-fd26-4555-b040-16bfdef679d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9580/2204803009.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.pivot_lsquare.loc[:, \"div\"] = (self.pivot_lsquare.loc[:, \"Square\"] / self.pivot_lsquare.loc[:, \"LifeSquare\"])\n",
      "/tmp/ipykernel_9580/2204803009.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.pivot_ksquare.loc[:, \"div\"] = self.pivot_ksquare.loc[:, \"Square\"] / self.pivot_ksquare.loc[:, \"KitchenSquare\"]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Categorical' with dtype category does not support reduction 'median'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m DataPreprocessor()\n\u001b[1;32m      2\u001b[0m preprocessor\u001b[38;5;241m.\u001b[39mfit(train_df)\n\u001b[0;32m----> 3\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m test_df \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransform(test_df)\n",
      "Cell \u001b[0;32mIn[8], line 109\u001b[0m, in \u001b[0;36mDataPreprocessor.transform\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    105\u001b[0m df\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShops_2\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Приводим в порядок показатель здравоохранения\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmedians \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHealthcare_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHealthcare_1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistrictId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistricts_healthcare)\n\u001b[1;32m    112\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHealthcare_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmedians\u001b[38;5;241m.\u001b[39mHealthcare_1, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)       \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:11623\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.median\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11606\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11607\u001b[0m     _num_doc,\n\u001b[1;32m  11608\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the median of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11621\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11622\u001b[0m ):\n\u001b[0;32m> 11623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:11212\u001b[0m, in \u001b[0;36mNDFrame.median\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(\n\u001b[1;32m  11206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11207\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11210\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11211\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmedian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10524\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  10520\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m  10522\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[1;32m  10523\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[0;32m> 10524\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10525\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor(res)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m  10526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:1534\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1532\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m-> 1534\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1535\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[1;32m   1537\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:339\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 339\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;66;03m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m    343\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[result]])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10485\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  10481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_1d_only_ea_dtype(values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m  10482\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr, ArrayManager\n\u001b[1;32m  10483\u001b[0m     ):\n\u001b[1;32m  10484\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_reduce(name, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m> 10485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m  10487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/arrays/base.py:1440\u001b[0m, in \u001b[0;36mExtensionArray._reduce\u001b[0;34m(self, name, skipna, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1442\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not support reduction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1443\u001b[0m     )\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m meth(skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Categorical' with dtype category does not support reduction 'median'"
     ]
    }
   ],
   "source": [
    "preprocessor = DataPreprocessor()\n",
    "preprocessor.fit(train_df)\n",
    "train_df = preprocessor.transform(train_df)\n",
    "test_df = preprocessor.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8e85a-6678-4538-97c4-e5f8f2a48783",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_gen = FeatureGenerator()\n",
    "features_gen.fit(train_df)\n",
    "train_df = features_gen.transform(train_df)\n",
    "train_df = features_gen.drop_outliers(train_df)\n",
    "test_df = features_gen.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4a244-5203-45db-8156-e7c7caab929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10), dpi= 80)\n",
    "sns.heatmap(train_df.corr(), xticklabels=train_df.corr().columns,\\\n",
    "            yticklabels=train_df.corr().columns, cmap='coolwarm', center=0, annot=True,\\\n",
    "           mask=np.triu(train_df.corr()), cbar_kws= {'orientation': 'horizontal'})\n",
    "\n",
    "# Decorations\n",
    "plt.title('Correlogram of mtcars', fontsize=22)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1677369-34e1-4f9d-84ca-b817afe47ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(train_df.drop([\"Price\",], axis=1), train_df.loc[:, \"Price\"],\n",
    "                     test_size=0.15, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe92fd2-4293-4c8d-b77a-686171136302",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=1600,\n",
    "                                max_depth=6,\n",
    "                                min_samples_leaf=10,\n",
    "                                learning_rate=.02,\n",
    "                                random_state=42,\n",
    "                                criterion='friedman_mse',\n",
    "                                max_features='sqrt', \n",
    "                                loss='huber',\n",
    "                                )\n",
    "gbr.fit(X_train, y_train.values.ravel())\n",
    "y_train_preds = gbr.predict(X_train)\n",
    "y_test_preds = gbr.predict(X_test)\n",
    "evaluate_preds(np.squeeze(y_train.values), y_train_preds)\n",
    "evaluate_preds(np.squeeze(y_test.values), y_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506dcc5-d2d1-4b93-b29a-2dfa19fb1c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(zip(X_train.columns, \n",
    "                                       gbr.feature_importances_), \n",
    "                                   columns=['feature_name', 'importance'])\n",
    "\n",
    "feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01f3ed-e407-4398-99fa-e69eb5d0d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(gbr.predict(test_df),\n",
    "                           index=test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0e8df-47fe-4460-aa36-7a9891e97c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f78c053-b473-4be5-8c0e-52c222433894",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('predict_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38424e3a-f6b8-4cca-b63c-cddba24200e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
